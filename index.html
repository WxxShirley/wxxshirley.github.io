
<!DOCTYPE html>
<html lang="en">
	<head>
		<meta charset="utf-8">
		<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
		<meta name="viewport" content="width=device-width, initial-scale=1">
		<meta name="google-site-verification" content="aSc5YLbeF55oadInzbW2R97pKbsed12qRJ1Gfaghb2A">
		<link rel="stylesheet" href="css/bootstrap.min.css">
		<link rel="stylesheet" type="text/css" href="css/style.css">
		<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
		<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
		<link rel="icon" href="images/icon.png" type="image/x-icon">
		<link href='http://fonts.googleapis.com/css?family=Source+Sans+Pro:200,300,400' rel='stylesheet' type='text/css'>
		<script type="text/javascript" src="js/bootstrap.min.js"></script>
		<title>Xixi's Homepage</title>
	</head>

	<body >
		<div id="page">
		<div id="inner-page">
		<div id="main">
			<div class="row row-thin">
				<div style="float:left;">
					<span style="font-weight:400;font-size:50px">Xixi WU </span><span style="font-size:28px; ">„ÄåÂê¥ËåúËåú„Äç</span><br/>
					<br/>
					<span>Ph.D. Student,</span><br/>
					<span>The Chinese University of Hong Kong</span><br/>
					<br/>

					<span>
						<a href="slides/CV_Xixi_Oct2025.pdf" class="my_link"><i class="fa fa-file"></i> CV</a> / 
						<a href="mailto:xxwu@se.cuhk.edu.hk" class="my_link"><i class="fa fa-envelope"></i> Email</a> /
						<a href="https://github.com/WxxShirley" class="my_link"><i class="fa fa-github"></i> GitHub</a> / 
						<a href="https://scholar.google.com/citations?user=VDW27LgAAAAJ&hl=en" class="my_link"><i class="ai ai-google-scholar-square"></i> Google Scholar</a> 
					</span><br/>

				</div>
				<div style="float:right">
					<img src="images/me.jpg" width="128" height="185" style="float:right;margin-top:0px;margin-bottom:0px"></img><br/>
				</div>
			</div> <!-- class="row" -->
			
			<div class="row row-thin">
				<div class="col-md-12">
					<hr>
				</div>
			</div> <!-- class="row" -->

			<div class="row row-thin">
				<div class="col-md-12 text-left">
					<h2>Short Bio</h2>
					<p>
						I am a Ph.D. student at The Chinese University of Hong Kong, under the supervision of <a href="https://www1.se.cuhk.edu.hk/~hcheng/">Prof. Hong CHENG</a>.
						Previously, I received my B.S. and M.S. in Computer Science from <a href="https://www.fudan.edu.cn/en/">Fudan University</a> in 2021 and 2024, respectively, under the supervision of <a href="https://openreview.net/profile?id=%7EYun_Xiong1">Prof. Yun XIONG</a>.
						<br/> 
					</p>
					<p>
						My research lies in enhancing the long-horizon <strong>planning</strong>, <strong>reasoning</strong>, and <strong>tool-use capabilities for language agents</strong>.
						I was a Research Intern at <a href="https://tongyi-agent.github.io/about/">Tongyi DeepResearch Team</a> <img src="images/company/tongyi-logo.jpg" alt="Tongyi Logo" style="height: 1.2em; vertical-align: top; margin-left: 2px;">, where I contributed to the development of Tongyi-DeepResearch-30B-A3B. 
						Prior to my works on LLMs, I conducted research on Graph Learning.
					</p>
				</div>
			</div>

			<div class="row row-thin">
				<div class="col-md-12">
					<div style="background-color: #ffe6e6; border: 1px solid #ffcccc; border-radius: 8px; padding: 15px; margin: 10px 0; text-align: center;">
						<p style="margin: 0; color: #d63384; font-weight: 500; font-size: 15px;">
							<strong>Open to Summer 2026 research internships in the US. Please contact me if you have such opportunities!</strong>
                        </p>
                    </div>
               </div>
            </div>

			<div class="row row-thin">
				<div class="news-container col-md-12 text-left">
					<h3 style="margin-top:5px; color: #0056b3;">Recent News</h3>
					<ul style="list-style-type: disc; padding-left: 20px;">
						<li>
							<span style="font-style: italic; color: #555;"><strong>[Oct 2025]</strong></span> 
						    Released <a href="https://github.com/Alibaba-NLP/DeepResearch/blob/main/Tech_Report.pdf" style="color: #0056b3; text-decoration: underline;">official technical report</a> for Tongyi-DeepResearch üëè
						</li>
						<li>
							<span style="font-style: italic; color: #555;"><strong>[Sep 2025]</strong></span> 
						    <a href="https://huggingface.co/Alibaba-NLP/Tongyi-DeepResearch-30B-A3B" style="color: #0056b3; text-decoration: underline;">Tongyi-DeepResearch-30B-A3B</a> achieves SOTA performance across open-source and proprietary agents on multiple benchmarks, accompanied by papers detailing the methods behind these achievements, <a href="https://arxiv.org/abs/2509.13313" style="color: #0056b3; text-decoration: underline;">ReSum</a>, a minimal extension to the ReAct paradigm that enables long-horizon search intelligence, and <a href="https://arxiv.org/abs/2509.13305" style="color: #0056b3; text-decoration: underline;">WebSailor-V2</a>, a scalable data synthesis and RL training pipeline.
						</li>
						<li>
							<span style="font-style: italic; color: #555;">[Aug 2025]</span> 
							Our paper <a href="https://github.com/WxxShirley/MoLoRAG" style="color: #0056b3; text-decoration: underline;">MoLoRAG</a> was accepted to <strong>EMNLP'2025</strong>. See you in Suzhou ‚ú®
						</li>
						<li>
							<span style="font-style: italic; color: #555;">[July 2025]</span> 
							Released <a href="https://arxiv.org/abs/2507.02592" style="color: #0056b3; text-decoration: underline;">WebSailor</a>, achieving open-source SOTA performance on challenging web browsing benchmarks. WebSailor topped the HuggingFace daily papers ü•á
						</li>
						<li>
							<span style="font-style: italic; color: #555;">[May 2025]</span> 
							Our paper <a href="https://llmnodebed.github.io/" style="color: #0056b3; text-decoration: underline;">LLMNodeBed</a> was accepted to <strong>ICML'2025</strong>. See you in Vancouver again üòÑ
						</li>
						<li>
							<span style="font-style: italic; color: #555;">[Nov 2024]</span> 
							I was awarded <a href="https://neurips.cc/Conferences/2024/ProgramCommittee" style="color: #0056b3; text-decoration: underline;">NeurIPS'2024 Top Reviewer</a> ü•≥
						</li>
						<li>
							<span style="font-style: italic; color: #555;">[Sep 2024]</span> 
							Our paper <a href="https://github.com/WxxShirley/GNN4TaskPlan" style="color: #0056b3; text-decoration: underline;">GNN4TaskPlan</a> was accepted to NeurIPS'2024. See you in Vancouver!
						</li>
					</ul>
				</div>
			</div>
			<br/>

			<div class="row row-thin">
				<div class="col-md-12 text-left">
					<h2>Research Highlights</h2>
				</div>
				<ul class="my_table">
					<li class="my_item">
						<div>
							<img src="images/research/resum.jpg" height="175" alt="generation" class="img_research"/>
						</div>
						<h4><strong>ReSum: Unbounded Inference Paradigm for Web Agents</strong></h4> 

						We introduce ReSum, a novel paradigm that enables indefinite exploration through periodic context summarization. ReSum minimizes modifications to ReAct to avoid additional architectural complexity, ensuring plug-and-play compatibility with existing agents. We further design ReSum-GRPO to familiarize agents with this paradigm. Experiments across web agents on three challenging benchmarks show average improvements of 4.5% for ReSum compared to ReAct, with further improvements of 8.2% after ReSum-GRPO training. 
						<br/>
						<div style="display: flex; align-items: center;">
							<img src="https://img.shields.io/github/stars/Alibaba-NLP/DeepResearch" style="float:left;"/>
						    <a href="https://arxiv.org/abs/2509.13313" class="paper-link"> [Paper] </a> <a href="https://github.com/Alibaba-NLP/DeepResearch/tree/main/WebAgent/WebResummer" class="code-link"> [Code] </a> <a href="https://tongyi-agent.github.io/blog/introducing-tongyi-deep-research/" class="blog-link"> [Blog] </a>
						</div>
					</li><br/>

					<li class="my_item">
						<div>
							<img src="images/research/websailor.jpg" height="150" alt="generation" class="img_research"/>
						</div>
						<h4><strong>WebSailor: Systematic Post-training Recipe for Web Agents</strong></h4> 

						WebSailor presents a comprehensive open-source framework for post-training web agents, encompassing data synthesis, supervised fine-tuning, and reinforcement learning components. Built on the Qwen3-30B-A3B model, WebSailor-V2 achieves SOTA performance, scoring 35.3% on BrowseComp-en, 44.1% on BrowseComp-zh, and 30.6% on Humanity's Last Exam (HLE).
						<br/>
						<div style="display: flex; align-items: center;">
							<img src="https://img.shields.io/github/stars/Alibaba-NLP/DeepResearch" style="float:left;"/>
						    <a href="https://arxiv.org/abs/2507.02592" class="paper-link"> [WebSailor-V1] </a> <a href="https://arxiv.org/abs/2509.13305" class="paper-link"> [WebSailor-V2] </a> 
						</div>
					</li><br/>


					<li class="my_item">
						<div>
							<img src="images/research/nodebed_poster.png" height="180" alt="generation" class="img_research"/>
						</div>
						<h4><strong>Benchmark of LLM4Graph Algorithms (ICML'2025)</strong></h4> 

						We introduce LLMNodeBed, a PyG-based testbed for LLM-based node classification algorithms. It integrates 14 datasets, supports 8 LLM-based and 8 classic methods, and covers 3 learning configurations.

                        With LLMNodeBed, we train and evaluate over 2,700 models to analyze the effects of factors like LLM type and size, prompt, learning paradigm, and dataset homophily. Our study reveals 8 key insights, including (1) <strong>optimal settings for each algorithm category</strong>, and (2) scenarios where <strong>LLMs significantly outperform LMs</strong>.

						<br/>
						<div style="display: flex; align-items: center;">
							<img src="https://img.shields.io/github/stars/WxxShirley/LLMNodeBed" style="float:left;"/>
						    <a href="https://arxiv.org/abs/2502.00829" class="paper-link"> [Paper] </a> <a href="https://github.com/WxxShirley/LLMNodeBed" class="code-link"> [Code] </a> <a href="slides/ICML2025NodeBed.pdf" class="slides-link"> [Poster] </a> <a href="https://zhuanlan.zhihu.com/p/1913536056717967976" class="blog-link"> [Blog] </a>
						</div>
					</li><br/>

					<li class="my_item">
						<div>
							<img src="images/research/taskplan_poster.png" height="180" alt="generation" class="img_research"/>
						</div>
						<h4><strong>Graph Learning for Task Planning (NeurIPS'2024)</strong></h4> 

						In language agents, available tasks naturally form a task graph, where nodes represent tasks and edges denote dependencies. Under such context, task planning involves selecting a path within this graph to fulfill user requests.
						We find that the bottleneck in LLMs' planning abilities lies in their limited understanding of the task graph. Therefore, we introduce GNNs as a simple fix, available in both training-free and training-required variants. Extensive experiments demonstrate that GNN-based methods surpass existing solutions even without training.
						<br/>
						<div style="display: flex; align-items: center;">
							<img src="https://img.shields.io/github/stars/WxxShirley/GNN4TaskPlan" style="float:left;"/>
						    <a href="https://arxiv.org/abs/2405.19119" class="paper-link"> [Paper] </a> <a href="https://github.com/WxxShirley/GNN4TaskPlan" class="code-link"> [Code] </a> <a href="slides/NIPS2024Plan.pdf" class="slides-link"> [Poster] </a> <a href="https://zhuanlan.zhihu.com/p/936340518" class="blog-link"> [Blog] </a>
						</div>
					</li><br/>
				</ul>
				</ul>
			</div><br/>

			<div class="row row-thin">
				<div class="col-md-12 text-left">
					<h2>Selected Publications</h2>
				</div>
				<ul class="my_table">
					<li class="my_item">
						<strong><a href="https://github.com/Alibaba-NLP/DeepResearch/blob/main/Tech_Report.pdf" class="title-link">Tongyi DeepResearch Technical Report</a></strong><br/>
						<span><strong>Xixi Wu</strong> is a co-author, contributed to the development of RL infrastructure for Tongyi-DeepResearch models.</span><br/>
						<em>Technical Report, 2025</em><br/>
						<div style="display: flex; align-items: center;">
							<img src="https://img.shields.io/badge/Large%20Language%20Models-purple" style="float:left; margin-right:0px" />
							<img src="https://img.shields.io/github/stars/Alibaba-NLP/DeepResearch" style="float: left;"/>
							<a href="https://github.com/Alibaba-NLP/DeepResearch" class="code-link">[Code]</a> 
							<a href="https://tongyi-agent.github.io/blog/introducing-tongyi-deep-research/" class="blog-link">[Blog]</a>
						</div>
					</li><br/>

					<li class="my_item">
						<strong><a href="https://arxiv.org/abs/2509.13313" class="title-link">ReSum: Unlocking Long-Horizon Search Intelligence via Context Summarization</a></strong><br/>
						<span><strong>Xixi Wu*</strong>, Kuan Li*, Yida Zhao, Liwen Zhang, Litu Ou, Huifeng Yin, Zhongwang Zhang, Xinmiao Yu, Dingchu Zhang, Yong Jiang, Pengjun Xie, Fei Huang, Minhao Cheng, Shuai Wang, Hong Cheng, and Jingren Zhou</span><br/>
						<em>arXiv preprint, 2025</em><br/>
						<div style="display: flex; align-items: center;">
							<img src="https://img.shields.io/badge/Large%20Language%20Models-purple" style="float:left; margin-right:0px" />
							<img src="https://img.shields.io/github/stars/Alibaba-NLP/DeepResearch" style="float: left;"/>
							<a href="https://github.com/Alibaba-NLP/DeepResearch/tree/main/WebAgent/WebResummer" class="code-link">[Code]</a> 
							<a href="https://tongyi-agent.github.io/blog/introducing-tongyi-deep-research/" class="blog-link">[Blog]</a>
						</div>
					</li><br/>

					<li class="my_item">
						<strong><a href="https://arxiv.org/abs/2509.07666" class="title-link">MoLoRAG: Bootstrapping Document Understanding via Multi-modal Logic-aware Retrieval</a></strong><br/>
						<span><strong>Xixi Wu</strong>, Yanchao Tan, Nan Hou, Ruiyang Zhang, and Hong Cheng</span><br/>
						<em>To appear, Proceedings of the Conference on Empirical Methods in Natural Language Processing (<strong>EMNLP</strong>), 2025</em><br/>
						<div style="display: flex; align-items: center;">
							<img src="https://img.shields.io/badge/Large%20Language%20Models-purple" style="float:left; margin-right:0px" />
							<a href="https://github.com/WxxShirley/MoLoRAG/" class="code-link" style="margin-left: 5px">[Code]</a> 
							<a href="slides/EMNLP2025MoLoRAG.pdf" class="slides-link">[Poster]</a> 
						</div>
					</li><br/>

					<li class="my_item">
						<strong><a href="https://arxiv.org/abs/2502.00829" class="title-link">When Do LLMs Help With Node Classification? A Comprehensive Analysis</a></strong><br/>
						<span><strong>Xixi Wu</strong>, Yifei Shen, Fangzhou Ge, Caihua Shan, Yizhu Jiao, Xiangguo Sun, and Hong Cheng</span><br/>
						<em>Proceedings of the 42nd International Conference on Machine Learning (<strong>ICML</strong>), 2025</em><br/>
						<div style="display: flex; align-items: center;">
							<img src="https://img.shields.io/badge/Large%20Language%20Models-purple" style="float:left; margin-right:0px" />
							<img src="https://img.shields.io/github/stars/WxxShirley/LLMNodeBed" style="float: left;"/>
							<a href="https://github.com/WxxShirley/LLMNodeBed/" class="code-link">[Code]</a> 
							<a href="slides/ICML2025NodeBed.pdf" class="slides-link">[Poster]</a> 
							<a href="https://llmnodebed.github.io/" class="blog-link">[Project Page]</a>
						</div>
					</li><br/>

					<li class="my_item">
						<strong><a href="https://arxiv.org/abs/2405.19119" class="title-link">Can Graph Learning Improve Planning in LLM-based Agents?</a></strong><br/>
						<span><strong>Xixi Wu*</strong>, Yifei Shen*, Caihua Shan, Kaitao Song, Siwei Wang, Bohang Zhang, Jiarui Feng, Hong Cheng, Wei Chen, Yun Xiong, and Dongsheng Li</span><br/>
						<em>Proceedings of the 38th Conference on Neural Information Processing Systems (<strong>NeurIPS</strong>), 2024</em><br/>
						<div style="display: flex; align-items: center;">
							<img src="https://img.shields.io/badge/Large%20Language%20Models-purple" style="float:left; margin-right:0px" />
							<img src="https://img.shields.io/github/stars/WxxShirley/GNN4TaskPlan" style="float: left;"/>
							<a href="https://github.com/WxxShirley/GNN4TaskPlan" class="code-link">[Code]</a> 
							<a href="slides/NIPS2024Plan.pdf" class="slides-link">[Poster]</a> 
							<a href="https://zhuanlan.zhihu.com/p/936340518" class="blog-link">[Blog]</a>
						</div>
					</li><br/>

					<li class="my_item">
						<strong><a href="https://arxiv.org/abs/2408.07369" class="title-link">ProCom: A Few-shot Targeted Community Detection Algorithm</a></strong><br/>
						<span><strong>Xixi Wu</strong>, Kaiyu Xiong, Yun Xiong, Xiaoxin He, Yao Zhang, Yizhu Jiao, and Jiawei Zhang</span><br/>
						<em>Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (<strong>KDD</strong>), 2024</em><br/>
					</li><br/>

					<li class="my_item">
						<strong><a href="https://arxiv.org/abs/2302.03555" class="title-link">ConsRec: Learning Consensus Behind Interactions for Group Recommendation</a></strong><br/>
						<span><strong>Xixi Wu</strong>, Yun Xiong, Yao Zhang, Yizhu Jiao, Jiawei Zhang, Yangyong Zhu, and Philip S. Yu</span><br/>
						<em>Proceedings of the ACM Web Conference (<strong>WWW</strong>), 2023</em><br/>
						<div style="display: flex; align-items: center;">
							<img src="https://img.shields.io/github/stars/FDUDSDE/WWW2023ConsRec" style="float:left;"/>
							<a href="https://github.com/FDUDSDE/WWW2023ConsRec" class="code-link">[Code]</a>
							<a href="slides/WWW2023ConsRec.pdf" class="slides-link">[Slides]</a>
							<a href="https://www.bilibili.com/video/BV1ZP411v7fu" class="video-link">[Video]</a>
						</div>
					</li><br/>

					<li class="my_item">
						<strong><a href="https://dl.acm.org/doi/abs/10.1145/3534678.3539370" class="title-link">CLARE: A Semi-supervised Community Detection Algorithm</a></strong><br/>
						<span><strong>Xixi Wu</strong>, Yun Xiong, Yao Zhang, Yizhu Jiao, Caihua Shan, Yiheng Sun, Yangyong Zhu, and Philip S. Yu</span><br/>
						<em>Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (<strong>KDD</strong>), 2022</em><br/>
						<div style="display: flex; align-items: center;">
							<img src="https://img.shields.io/github/stars/FDUDSDE/KDD2022CLARE" style="float: left;"/>
							<a href="https://github.com/FDUDSDE/KDD2022CLARE" class="code-link">[Code]</a> 
							<a href="slides/KDD2022CLARE.pdf" class="slides-link">[Slides]</a> 
							<a href="https://bilibili.com/video/BV1As4y1C7mX" class="video-link">[Video]</a>
						</div>
					</li><br/>

					<li class="my_item">
						<strong><a href="https://arxiv.org/abs/2402.11472" class="title-link">DDIPrompt: Drug-Drug Interaction Event Prediction based on Graph Prompt Learning</a></strong><br/>
						<span>Yingying Wang, Yun Xiong, <strong>Xixi Wu</strong>, Xiangguo Sun, Jiawei Zhang, and Guangyong Zheng</span><br/>
						<em>Proceedings of the 33rd ACM International Conference on Information and Knowledge Management (<strong>CIKM</strong>), 2024</em><br/>
					</li><br/>

					<li class="my_item">
						<strong><a href="https://arxiv.org/abs/2406.11891" class="title-link">Towards Adaptive Neighborhood for Advancing Temporal Interaction Graph Modeling</a></strong><br/>
						<span>Siwei Zhang, Xi Chen, Yun Xiong, <strong>Xixi Wu</strong>, Yao Zhang, Yongrui Fu, Yinglong Zhao, and Jiawei Zhang</span><br/>
						<em>Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (<strong>KDD</strong>), 2024</em><br/>
					</li><br/>

					<li class="my_item">
						<strong><a href="https://arxiv.org/abs/2308.05013" class="title-link">Dual Intents Graph Modeling for User-centric Group Discovery</a></strong><br/>
						<span><strong>Xixi Wu</strong>, Yun Xiong, Yao Zhang, Yizhu Jiao, and Jiawei Zhang</span><br/>
						<em>Proceedings of the 32nd ACM International Conference on Information and Knowledge Management (<strong>CIKM</strong>), 2023</em><br/>
					</li><br/>

				</ul>
			</div>
            

			<div class="row row-thin">
				<div class="col-md-12 text-left">
					<h2>Experience</h2>
				</div>
				<ul class="my_table">
					<li class="my_item">
						<img src="images/company/microsoft.jpg" style="margin-top:0px; margin-left: 26px; margin-right: 30px;" width="45" height="45" alt="generation"/>
						<div><p>
							<strong> Microsoft Research Asia </strong><br/>
							<em>Research Intern, Shanghai AI/ML Group</em>
							<span class="date">Feb. 2024 - Jun. 2024</span><br/><br/>
						</p></div>
					</li>
					<li class="my_item">
						<img src="images/company/tongyi-logo.jpg" style="margin-top:5px; margin-left: 26px; margin-right: 30px;" width="48" height="48" alt="generation" />
						<div><p>
							<strong> Tongyi Lab, Alibaba Group </strong><br/>
							<em>Research Intern, DeepResearch Team</em>
							<span class="date">Jun. 2025 - Oct. 2025</span><br/>
						</p></div>
					</li>
				</ul>
			</div><br/>

			
			<div class="row row-thin">
				<div class="col-md-12 text-left">
					<h2>Selected Awards</h2>
				</div>
				<ul class="my_table">
					<li>
						Hong Kong PhD Fellowship (HKPFS), Hong Kong SAR
						<span class="date">2024</span>
					</li>
					<li>
						National Scholarship for Graduate Student, Ministry of Education, China
						<span class="date">2022 & 2023</span>
					</li>
					<li>
						ACM Web Conference Student Travel Award
						<span class="date">2023</span>
					</li>
					<li>
						Second Class Scholarship for Outstanding Student, Fudan University
						<span class="date">2018 & 2021</span>
					</li>
					<li>
						Second Prize of Undergraduate Mathematical Contest in Modeling, Shanghai, China (CUMCM)
						<span class="date">2019</span>
					</li>
					<li>
						First Prize in National Olympiad in Mathematics in Provinces, Jiangsu, China 
						<span class="date">2016</span>
					</li>
					
				</ul>
			</div><br/>

			<div class="row row-thin">
				<div class="col-md-12 text-left">
					<h2>Professional Services</h2>
					<ul>
						<li>
							<strong>Conference Reviewer:</strong> NeurIPS'2024 (<strong>Top Reviewer AwardüèÜ</strong>) - 2025, ICLR'2025 - 2026, ICML'2025, WWW'2024 Graph Foundation Model (GFM) Workshop, SIGKDD'2024 - 2025, AAAI 2026
						</li>
						<li>
							<strong>Journal Reviewer: </strong> IEEE Transactions on Knowledge and Data Engineering (<strong>TKDE</strong>), Transactions on Machine Learning Research (<strong>TMLR</strong>)
						</li>
					</ul>
				</div>
			</div><br/>


			<div class="row row-thin">
				<div class="col-md-12 text-left">
					<h2>Miscellaneous</h2>
					<ul>
						<li>I love sports like swimming üèä and running üèÉ. I also enjoy cooking Chinese food ü§£ </li>
	                        
						<li>During my undergraduate studies, I was interested in mobile app development (You can find all the source codes on my GitHub):
							<table>
								<tr>
									<td style="padding: 10px; text-align: center;">
										<img src="images/project/lose-weight.png" style="width: 60px; margin: 5px;">
										<img src="images/project/lose-weight.png" style="width: 60px; margin: 5px;">
										<p><em><strong><a href="https://github.com/WxxShirley/LoseWeight" class="title-link">Lose Weight</a></strong>, a Fluter App</em></p>
										
									</td>

									<td style="padding: 10px; text-align: center;">
										<img src="images/project/QR.jpeg" style="width: 110px; margin-left: 20px; margin-right: 20px; margin-top: 5px; margin-bottom: 5px;">
									
										<p><em><strong><a href="https://github.com/WxxShirley/SE-Travel" class="title-link">Hulv</a></strong>, a Mini-Program</em></p>
									</td>

									<td style="padding: 10px; text-align: center;">
										<img src="images/project/chatroom.png" style="width: 140px; margin: 5px;">		
										<p><em><strong><a href="https://github.com/WxxShirley/Chatroom" class="title-link">Chatroom</a></strong>, a Desktop App</em></p>
									</td>


								</tr>
							</table>

						</li>

						<li>
							I enjoy exploring the unknown and strive to keep moving forward on this path of discovery and learning ‚ú®
						</li>

					</ul>
				</div>
			</div>
			<br/>

		</div> <!-- class="main" -->

		<p align="center" width="200" style="margin-top:30px;">
			<a href="https://clustrmaps.com/site/1bwhn"  title="Visit tracker"><img src="//www.clustrmaps.com/map_v2.png?d=QfDMfsfFQX5Sbm_3on4wMmjwODxm5gLZT1lU2FsMz1s&cl=ffffff" /></a>
		</p>

		<div style="padding:14px 0px 30px 0px;text-align:center;color:#d9d9d9;clear:both">
			Last updated at Oct 29, 2025 by Xixi
		</div>

		</div> <!-- class="inner page" -->
		</div> <!-- class="page" -->
	</body>
</html>
